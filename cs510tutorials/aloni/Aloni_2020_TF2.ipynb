{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code here originated with a Blog post by Dan Aloni. Here is the link:\n",
    "\n",
    "https://blog.aloni.org/posts/backprop-with-tensorflow/\n",
    "\n",
    "Please do visit this blog since the commentary included there is valuable and despite embedding this example in Jupyter is not full carried across to here. \n",
    "\n",
    "Some context - I have greatly appreciated Dan Alone's original post and we have developed several variants over the past three years in CS510. Important for this version is it has been updated to run with TF2.\n",
    "\n",
    "New here relative to the original blog post is code to visualize what the first hidden layer is learning.  This hopefully provides additional insight into the feature learning process - something which for more complex networks is extremely hard to intuit. \n",
    "\n",
    "Running on a MacBook Pro with Catalina the following will buid the necessary environment from scratch using anaconda. \n",
    "\n",
    "`conda create --name aloni2 ...................`\n",
    "\n",
    "Ross Beveridge\n",
    "April 8, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most of this is standard.  The two lines using the os package are a hack I found necessary to run on Catalina.\n",
    "# The adaptation to use a local version of the dataset library makes for a more self contained example. \n",
    "\n",
    "import matplotlib\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "matplotlib.use('Qt5Agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version has gone back to the original data loading and handling in the original blog post.  For awhile we used an alternative.  Key to making this work is sometimes needing to hand load the support code for the MNIST data. Here are detailed instructions:\n",
    "\n",
    "There will be a folder in your storage space for 'anaconda' which contains all the files for anaconda distribution (fore me it is 'anaconda3').\n",
    "\n",
    "Inside this folder you will find 'envs' folder, which has sub-folders for anaconda environments.\n",
    "\n",
    "One of these will be the tensorflow 2 environment folder, the folder name will be the same as your environment name. The tensorflow package is installed in the python site-packages. Inside your environment folder you will find the following folder path:\n",
    "\n",
    "'lib/python3.x/site-packages/tensorflow_core/`\n",
    "\n",
    "Place the files from https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/tutorials/mnist in the subfolder examples/tutorials/mnist . On my installation the full path looks like ‘’.\n",
    "\n",
    "`/Users/ross/opt/anaconda3/envs/tfcv/lib/python3.7/site-packages/tensorflow_core/examples/tutorials/mnist`\n",
    "\n",
    "My thanks to Saurabh Deotale for setting me on the correct path to make this option work. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-8bf8ae5a5303>:2: read_data_sets (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as: tensorflow_datasets.load('mnist')\n",
      "WARNING:tensorflow:From /Users/ross/opt/anaconda3/envs/tfcv/lib/python3.7/site-packages/tensorflow_core/examples/tutorials/mnist/input_data.py:297: _maybe_download (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/ross/opt/anaconda3/envs/tfcv/lib/python3.7/site-packages/tensorflow_core/examples/tutorials/mnist/input_data.py:299: _extract_images (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/ross/opt/anaconda3/envs/tfcv/lib/python3.7/site-packages/tensorflow_core/examples/tutorials/mnist/input_data.py:304: _extract_labels (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/ross/opt/anaconda3/envs/tfcv/lib/python3.7/site-packages/tensorflow_core/examples/tutorials/mnist/input_data.py:112: _dense_to_one_hot (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/ross/opt/anaconda3/envs/tfcv/lib/python3.7/site-packages/tensorflow_core/examples/tutorials/mnist/input_data.py:328: _DataSet.__init__ (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/_DataSet.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we establish the variables which constitute the layers of the network, the inputs a_0, the outputs y, and the internal weights and offsets.  Note the randomized initialization of the weights and offsets is on by default. Go ahead, turn it off and start with nice clean zeroes for all the weights and offsets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ross/opt/anaconda3/envs/tfcv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "a_0 = tf.compat.v1.placeholder(tf.float32, [None, 784])\n",
    "y = tf.compat.v1.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "middle  = 30\n",
    "raninit = True\n",
    "\n",
    "if raninit :\n",
    "    w_1 = tf.Variable(tf.random.truncated_normal([784, middle]))\n",
    "    b_1 = tf.Variable(tf.random.truncated_normal([1, middle]))\n",
    "    w_2 = tf.Variable(tf.random.truncated_normal([middle, 10]))\n",
    "    b_2 = tf.Variable(tf.random.truncated_normal([1, 10]))\n",
    "else :\n",
    "    w_1 = tf.Variable(tf.zeros([784, middle]))\n",
    "    b_1 = tf.Variable(tf.zeros([1, middle]))\n",
    "    w_2 = tf.Variable(tf.zeros([middle, 10]))\n",
    "    b_2 = tf.Variable(tf.zeros([1, 10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next code block makes the non-linear function mapping input to output for units and that function's first partial derivative explicit.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-475eefe3aff5>:3: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "def sigma(x):\n",
    "    return tf.compat.v1.div(tf.constant(1.0),\n",
    "                  tf.add(tf.constant(1.0), tf.exp(tf.negative(x))))\n",
    "\n",
    "z_1 = tf.add(tf.matmul(a_0, w_1), b_1)\n",
    "a_1 = sigma(z_1)\n",
    "z_2 = tf.add(tf.matmul(a_1, w_2), b_2)\n",
    "a_2 = sigma(z_2)\n",
    "\n",
    "def sigmaprime(x):\n",
    "    return tf.multiply(sigma(x), tf.subtract(tf.constant(1.0), sigma(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next body of code establishes what is in effect a second network which carries out the backpropogation calculation. Note in particular the error signal `diff` and the learning rate `eta`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = tf.subtract(a_2, y)\n",
    "\n",
    "d_z_2 = tf.multiply(diff, sigmaprime(z_2))\n",
    "d_b_2 = d_z_2\n",
    "d_w_2 = tf.matmul(tf.transpose(a=a_1), d_z_2)\n",
    "\n",
    "d_a_1 = tf.matmul(d_z_2, tf.transpose(a=w_2))\n",
    "d_z_1 = tf.multiply(d_a_1, sigmaprime(z_1))\n",
    "d_b_1 = d_z_1\n",
    "d_w_1 = tf.matmul(tf.transpose(a=a_0), d_z_1)\n",
    "\n",
    "eta = tf.constant(0.5)\n",
    "step = [\n",
    "    tf.compat.v1.assign(w_1,\n",
    "            tf.subtract(w_1, tf.multiply(eta, d_w_1)))\n",
    "  , tf.compat.v1.assign(b_1,\n",
    "            tf.subtract(b_1, tf.multiply(eta,\n",
    "                               tf.reduce_mean(input_tensor=d_b_1, axis=[0]))))\n",
    "  , tf.compat.v1.assign(w_2,\n",
    "            tf.subtract(w_2, tf.multiply(eta, d_w_2)))\n",
    "  , tf.compat.v1.assign(b_2,\n",
    "            tf.subtract(b_2, tf.multiply(eta,\n",
    "                               tf.reduce_mean(input_tensor=d_b_2, axis=[0]))))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual code to train and report on the performance of the network follows.  Here the code departs from the origianl Blog post in several ways including the introduction of the ability to visually inspect hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "acct_mat = tf.equal(tf.argmax(input=a_2, axis=1), tf.argmax(input=y, axis=1))\n",
    "acct_res = tf.reduce_sum(input_tensor=tf.cast(acct_mat, tf.float32))\n",
    "\n",
    "sess = tf.compat.v1.InteractiveSession()\n",
    "w_1_before = ''\n",
    "w_1_after  = ''\n",
    "\n",
    "def run_training(n,m) :\n",
    "    global w_1_before\n",
    "    global w_1_after\n",
    "    k = 0\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    w_1_before = sess.run(w_1)\n",
    "    for i in range(n):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(10)\n",
    "        sess.run(step, feed_dict = {a_0: batch_xs,\n",
    "                                y : batch_ys})\n",
    "        if i % m == 0:\n",
    "            k = k + 1\n",
    "            res = sess.run(acct_res, feed_dict =\n",
    "                       {a_0: mnist.test.images[:1000],\n",
    "                        y : mnist.test.labels[:1000]})\n",
    "            stout = 'Step ' + repr(k) + ' Num Correct ' + repr(res)\n",
    "            print(stout)\n",
    "            #print(sess.run(w_1)[404:409,0])\n",
    "    w_1_after = sess.run(w_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 Num Correct 95.0\n",
      "Step 2 Num Correct 772.0\n",
      "Step 3 Num Correct 816.0\n",
      "Step 4 Num Correct 817.0\n",
      "Step 5 Num Correct 829.0\n",
      "Step 6 Num Correct 828.0\n",
      "Step 7 Num Correct 825.0\n",
      "Step 8 Num Correct 839.0\n",
      "Step 9 Num Correct 834.0\n",
      "Step 10 Num Correct 846.0\n"
     ]
    }
   ],
   "source": [
    "run_training(10000,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next three functions are useful for actually exploring the network weights before and after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_weight_before(node) :\n",
    "    dimg = np.reshape(w_1_before[:,node],(28,28))\n",
    "    plt.imshow(dimg)\n",
    "    plt.show()\n",
    "    \n",
    "def show_weight_after(node) :\n",
    "    dimg = np.reshape(w_1_after[:,node],(28,28))\n",
    "    plt.imshow(dimg)\n",
    "    plt.show()\n",
    "    \n",
    "def show_weight_change(node) :\n",
    "    diff = w_1_before - w_1_after\n",
    "    dimg = np.reshape(diff[:,node],(28,28))\n",
    "    plt.imshow(dimg)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
